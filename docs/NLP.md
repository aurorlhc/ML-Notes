# NLP



### tf–idf
tf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.

The tf-idf value increases proportionally to the
* number of times a word appears in the document, 
* but is often offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general

![](https://wikimedia.org/api/rest_v1/media/math/render/svg/10109d0e60cc9d50a1ea2f189bac0ac29a030a00)

Term frequency
The weight of a term that occurs in a document is simply proportional to the term frequency

Inverse document frequency
The specificity of a term can be quantified as an inverse function of the number of documents in which the word occurs
